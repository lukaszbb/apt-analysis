A Look at Targeted Attacks Through the Lense of an NGO

Stevens Le Blond1
Zheng Leong Chua2

Adina Uritesc1
Prateek Saxena2

C´edric Gilbert1
Engin Kirda3

1MPI-SWS

2National Univ. of Singapore

3Northeastern Univ.

Abstract

We present an empirical analysis of targeted attacks
against a human-rights Non-Governmental Organization
(NGO) representing a minority living in China. In par-
ticular, we analyze the social engineering techniques, at-
tack vectors, and malware employed in malicious emails
received by two members of the NGO over a four-year
period. We ﬁnd that both the language and topic of
the emails were highly tailored to the victims, and that
sender impersonation was commonly used to lure them
into opening malicious attachments. We also show that
the majority of attacks employed malicious documents
with recent but disclosed vulnerabilities that tend to
evade common defenses. Finally, we ﬁnd that the NGO
received malware from different families and that over a
quarter of the malware can be linked to entities that have
been reported to engage in targeted attacks against polit-
ical and industrial organizations, and Tibetan NGOs.
1 Introduction
In the last few years, a new class of cyber attacks has
emerged that is more targeted at individuals and organi-
zations. Unlike their opportunistic, large-scale counter-
parts, targeted attacks aim to compromise a handful of
speciﬁc, high-value victims. These attacks have received
substantial media attention, and have successfully com-
promised a wide range of targets including critical na-
tional infrastructures [19], Fortune 500 companies [23],
news agencies [20], and political dissidents [10, 11, 16].
Despite the high stakes involved in these attacks, the
ecosystem sustaining them remains poorly understood.
The main reason for this lack of understanding is that vic-
tims rarely share the details of a high-proﬁle compromise
with the public, and they typically do not disclose what
sensitive information has been lost to the attackers. Ac-
cording to folk wisdom, attackers carrying out targeted
attacks are generally thought to be state-sponsored. Ex-
amples of national organizations that have been reported
to be engaged in targeted attacks include the NSA’s of-

ﬁce of Tailored Access Operations (TAO) [3] and the
People’s Liberation Army’s Unit 61398 [15]. Recently,
researchers also attributed attacks in the Middle East to
the governments of Bahrain, Syria, and the United Arab
Emirates [16].

There now exists public evidence that virtually every
computer system connected to the internet is susceptible
to targeted attacks. The Stuxnet attack even successfully
compromised air-gapped Iranian power plants [19] and
was able to damage the centrifuges in the facility. More
recently, Google, Facebook, the New York Times, and
many other global companies have been compromised
by targeted attacks. Furthermore, political dissidents and
Non-Governmental Organizations (NGOs) are also being
targeted [10, 11, 16].

In this paper, we analyze 1,493 suspicious emails col-
lected over a four-year period by two members of the
World Uyghur Congress (WUC), an NGO representing
an ethnic group of over ten million individuals mainly
living in China. WUC volunteers who suspected that
they were being speciﬁcally targeted by malware shared
the suspicious emails that they received with us for anal-
ysis. We ﬁnd that these emails contain 1,176 malicious
attachments and target 724 unique email addresses be-
longing to individuals afﬁliated with 108 different orga-
nizations. This result indicates that, despite their targeted
content, these attacks were sent to several related victims
(e.g., via Cc). Although the majority of these targeted or-
ganizations were NGOs, they also comprised a few high-
proﬁle targets such as the New York Times and US em-
bassies.

We leverage this dataset to perform an empirical anal-
ysis of targeted attacks in the wild. First, we analyze
the engineering techniques and ﬁnd that the language
and topic of the malicious emails were tailored to the
mother tongue and level of specialization of the victims.
We also ﬁnd that sender impersonation was common and
that some attacks in our dataset originated from com-
promised email accounts belonging to high-proﬁle ac-

1

tivists. Second, whereas recent studies report that ma-
licious archives and executables represented the majority
of the targeted-attack threat [15, 22], we ﬁnd that mali-
cious documents were the most common attack vector in
our dataset. Although we do not ﬁnd evidence of zero-
day vulnerabilities, we observe that most attacks used re-
cent vulnerabilities, that exploits were quickly replaced
to adapt to new defense mechanisms, and that they of-
ten bypassed common defenses. Third, we perform an
analysis of the ﬁrst-stage malware delivered over these
malicious emails and ﬁnd that WUC has been targeted
with different families of malware over the last year. We
ﬁnd that over a quarter of these malware samples exhib-
ited similarities with those used by entities reported to
have carried out targeted attacks.

Our work complements existing reports on targeted at-
tacks such as GhostNet, Mandiant, and Symantec Inter-
net Security Threat (ISTR) 2013 [11, 15, 22]. Whereas
the GhostNet and Mandiant reports focus on the attack
lifecycle after the initial compromise, this study provides
an in-depth analysis of the reconnaissance performed be-
fore the compromise. We note that both approaches have
pros and cons and are complementary: While it is hard
for the authors of these reports to know how a system be-
came compromised in retrospect, it is equally hard for us
to know if the observed attacks will compromise the tar-
geted system(s). Finally, whereas ISTR provides some
numbers about reconnaissance analysis for industrial-
espionage attacks [22], we present a thorough and rig-
orous analysis of the attacks in our dataset.

Finally, to foster research in this area, we release our

dataset of targeted malware to the community [4].
Scope. Measuring real-world targeted attacks is chal-
lenging and this paper has a number of important bi-
ases. First, our dataset contains mainly attacks against
the Uyghur and human-rights communities. While the
speciﬁcs of the social engineering techniques (e.g., use
of Uyghur language) will vary from one targeted com-
munity to another, we argue that identifying commonly
used techniques (e.g., topic, language, senders’ imper-
sonation) and their purpose is a necessary step towards
designing effective defenses. Another limitation of our
dataset is that it captures only targeted attacks carried out
over email channels and that were detected by our vol-
unteers. Although malicious emails seem to constitute
the majority of targeted attacks, different attack vectors
such as targeted drive-by downloads are equally impor-
tant. Finally, we reiterate that the goal of this study is to
understand the reconnaissance phase occurring before a
compromise. Analyzing second-stage malware, monitor-
ing compromised systems, and determining the purpose
of targeted attacks are all outside of the scope of this pa-
per and are the topic of recent related work [10, 16]. We
discuss open research challenges in Section 6.

Figure 1: Screenshot of a malicious email with an im-
personated sender, and a malicious document exploit-
ing Common Vulnerabilities and Exposures (CVE) num-
ber 2012-0158 and containing malware. The email re-
plays an actual announcement about a conference in
Geneva and was edited by the attacker to add that all
fees would be covered.

2 Overview

Context. WUC, the NGO from which we have received
our dataset, represents the Uyghurs, an ethnic minority
concentrated in the Xinjiang region in China. Xinjiang
is the largest Chinese administrative division, has abun-
dant natural resources such as oil, and is China’s largest
natural gas-producing region. WUC frequently engages
in advocacy and meeting with politicians and diplomats
at the EU and UN, as well as collaborating with a variety
of NGOs. Rebiya Kadeer, WUC’s current president, was
the ﬁfth richest person in China before her imprisonment
for dissent in 1996, and is now in exile in the US. Fi-
nally, WUC is partly funded by the National Endowment
for Democracy (NED), a US NGO itself funded by the
US Congress to promote democracy. (We will see below
that NED has been targeted with the same malware as
WUC.)

WUC has been a regular target of Distributed De-
nial of Service (DDoS) attacks and telephone disrup-
tions, as well as targeted attacks. For example, the
WUC’s website became inaccessible from June 28 to
July 10, 2011 due to such a DDoS attack. Concurrently
to this attack, the professional and private phone lines of
WUC employees were ﬂooded with incoming calls, and
the WUC’s contact email address received 15,000 spam
emails in one week.
Data acquisition.
In addition to these intermittent
threats, WUC employees constantly receive suspicious
emails impersonating their colleagues and containing

2

malicious links and attachments. These emails consis-
tently evade spam and malware defenses deployed by
webmail providers and are often relevant to WUC’s ac-
tivities. In fact, our volunteers claim that the emails are
often so targeted that they need to conﬁrm their legiti-
macy with the impersonated sender in person. For ex-
ample, Figure 1 shows the screenshot of such an email
that replays the actual announcement for a conference in
Geneva organized by WUC. As a result, WUC members
are wary of any emails containing links or attachments,
and some of them save these emails for future inspec-
tion. We came in contact with two WUC employees who
shared the suspicious emails that they had received (with
consent from WUC). The authors of this work were not
involved in the data collection.
Characteristics of the dataset. The two volunteers
shared with us the headers and content of 1,493 suspi-
cious emails that they received over a four-year period.
1,178 (79%) of these emails were sent to the private
email addresses of the two NGO employees from whom
we obtained the data, 16 via the public email address of
the WUC, and the remaining 299 emails were forwarded
to them (126 of these by colleagues at WUC). Overall,
89% of these emails were received directly by our volun-
teers or their colleagues at WUC. As we will see below,
they also contain numerous email addresses in the To and
Cc ﬁelds belonging to individuals that are not afﬁliated
with WUC.

The emails contained 209 links and 1,649 attachments,
including 1,176 with malware (247 RAR, 49 ZIP, 144
PDF, and 655 Microsoft Ofﬁce ﬁles, and 81 ﬁles in other
formats). Our analysis revealed 1,116 malicious emails
containing malware attachments. (We were not able to
verify the maliciousness of the links as most of them
were invalid by the time we obtained the data.) In the fol-
lowing, we analyze malicious emails exclusively and we
refer to malicious archives or documents depending on
whether they contained RAR or ZIP, PDF or Microsoft
Ofﬁce documents, respectively. Finally, the volunteers
labeled the data wherever necessary, enabling us, for ex-
ample, to establish that the sender of the emails was im-
personated for 84% of the emails. Table 1 summarizes
the main characteristics of these malicious emails.
Scope of the dataset. Analyzing the headers of the ma-
licious emails revealed a surprisingly large number of re-
cipients in the To or Cc ﬁelds. In particular, we observed
that malicious emails had been sent to 1,250 unique
email addresses and 157 organizations. A potential ex-
planation for this behavior could be that the attacker tam-
pered with the email headers (e.g., via a compromised
SMTP server) as part of social engineering so these
emails were only delivered to our volunteers, despite
the additional indicated recipients. To test this hypoth-
esis, we considered only those emails received directly

by our volunteers, originating from well-known webmail
domains (i.e., aol.com, gmx.de, gmx.com, gmail.com,
googlemail.com, hotmail.com, outlook.com, and ya-
hoo.com), and veriﬁed via Sender Policy Framework
(SPF) and DomainKeys Identiﬁed Mail (DKIM). SPF
and DKIM are methods commonly used to authenticate
the sending server of an email message. By verifying
that these malicious emails originated from well-known
webmail servers, we obtain 568 malicious emails whose
headers are very unlikely to have been tampered with by
the attacker. By repeating our above analysis on these
emails only, we obtain 724 unique email addresses and
108 organizations. Other organizations besides WUC
include NED (WUC’s main source of funding and it-
self funded by the US congress), the New York Times,
and US embassies. In summary, while we obtained our
dataset from two volunteers working for a single orga-
nization, it offers substantial coverage not only of one
NGO, but also of those attacks against multiple NGOs in
which attackers target more than one organization with
the same email. We show the full list of organizations
targeted in our dataset in Appendix A.

What are targeted attacks? There is no precise deﬁni-
tion of targeted attacks. In this paper, we loosely deﬁne
these attacks as low-volume, socially engineered com-
munication which entices speciﬁc victims into installing
malware. In the dataset we analyze here, the communi-
cation is by email, and the mechanism of exploitation is
primarily using malicious archives or documents. A tar-
geted victim, in this work, refers to speciﬁc individuals,
or an organization as a whole. When necessary, we also
use the term volunteer(s) to distinguish between our two
collaborators and other victims.

The terms targeted attacks and Advanced Persistent
Threats (or APTs) are often used interchangeably. As
this paper focuses on the reconnaissance phase of tar-
geted attacks (occurring before a compromise), we can-
not measure how long attackers would have remained in
control of the targeted systems (i.e., their persistency).
As a result, we simply refer to these attacks as targeted
attacks, and not APTs, throughout the rest of this pa-
per. We discuss speciﬁc social engineering characteris-
tics that make targeted attacks difﬁcult to detect by un-
suspecting average users in Section 3, the attack vectors
used in our dataset in Section 4, and the malware fam-
ilies they install in Section 5. Finally, we will discuss
open research challenges in Section 6.

Ethics. The dataset was collected prior to our contact-
ing WUC and for the purpose of future security analysis.
Furthermore, WUC approved the disclosure of all the in-
formation contained in this paper and requested that the
organization’s name not be anonymized.

3

Table 1: Summary of our dataset originating from two volunteers. Malicious indicates the fraction of emails containing
malware, Impersonated the fraction of emails with an impersonated sender, # recipients and # orgs the number of
unique email addresses that were listed in the To and Cc ﬁelds of the malicious emails and the corresponding number
of organizations, respectively.

1st volunteer
2nd volunteer

Total

Beginning - end

Sept 2012 - Sept 2013
Sept 2009 - Jul 2013
Sept 2009 - Sept 2013

Size
98 MB
818 MB
916 MB

Malicious

154/241 (64%)
962/1,252 (77%)
1,116/1,493 (75%)

Impersonated

(92%)
141/154
802/962
(83%)
943/1,116 (84%)

# recipients

# orgs

124
666
724

25
102
108

3 Analysis of social engineering

The GhostNet, Mandiant, ISTR, and other reports [11,
15, 22] mention the use of socially-engineered emails to
lure their victims into installing malware, clicking on
malicious links, or opening malicious documents. For
example, the GhostNet report refers to one spoofed email
containing a malicious DOC attachment, and the Man-
diant report to one email sent from a webmail account
bearing the name of the company’s CEO enticing several
employees to open malware contained in a ZIP archive.
Concurrent work reports the use of careful social engi-
neering against civilians and NGOs in the Middle East
[16] and also Tibetan and human-rights NGOs [10]. De-
spite this anecdotal evidence, we are not aware of any
rigorous and thorough analysis of the social engineering
techniques employed in targeted attacks. In this section,
we seek to answer the following questions in the context
of our dataset:

(cid:15) What social

traits of victims are generally ex-
ploited? Do attackers generally impersonate a
sender known to the victim and if so who do they
choose to impersonate?

(cid:15) Who are the victims? Are malicious emails sent
only to speciﬁc individuals, to entire organizations,
or communities of users?

(cid:15) When are users being targeted? When do users
start being targeted? Are the same users frequently
being targeted and for how long? Are several
users from the same organization being targeted
simultaneously?

3.1 Methodology
The analysis below focuses on 1,116 malicious emails
received between 2009 and 2013.
Topics and language. To attempt to understand how
well the attacker knows his victims, we manually catego-
rized the emails (coded) by topic and language. (Unless

indicated otherwise, the analysis below was performed
on emails that were coded by one of the author.) The
topic was determined by reading the emails’ titles and
bodies and, in cases where emails were not written in En-
glish, we also used an online translation service. Emails
whose topic was still unclear after using the translator
were labeled as Unknown.
Targeted victims. To determine the targeted victims
of these attacks, we searched the email addresses and
full names of the senders and receivers for the mali-
cious emails originating from trustworthy SMTP servers.
When available, we used their public proﬁles available
on social media websites such as Google, Facebook, and
Skype to determine their professional positions and or-
ganizations. We assume we have found the social proﬁle
of a victim if one of the three following rules applies (in
that order): First, if the social proﬁle refers directly to
the email address seen in the malicious email; second,
if the social proﬁle refers to an organization whose do-
main matches the victims’ email address; or third, if we
ﬁnd contextual evidence that the social proﬁle is linked
to WUC, Uyghurs, or the topic of the malicious email.
Out of 724 victims’ email addresses, we found the pro-
ﬁle of 32% (237), 4% (30), and 23% (167) using the ﬁrst,
second, and last rule, respectively.
Organizations and industries. In the following, WUC
refers to victims directly afﬁliated with the organiza-
tion (including our volunteers). Other Uyghur NGOs
include Australia, Belgium, Canada, Finland, France,
Japan, Netherlands, Norway, Sweden, and UK associa-
tions. Other NGOs include non-proﬁt organizations such
as Amnesty International, Reporters Without Borders,
and Tibetan NGOs. Academia, Politics, and Business
contain victims working in these industries. Finally, Un-
known corresponds to victims for which we were not able
to determine an afﬁliation.
Ranks. We also translated the professional positions
of the victims into one of the three categories: High,
Medium, and Low proﬁle. We consider professional lead-
ership positions such as chairpersons, presidents, and ex-
ecutives as high-proﬁle, job positions such as assistants,
and IT personnel as medium-proﬁle, and unknown and
shared email addresses (e.g., NGO’s contact informa-
tion) as low-proﬁle.

4

known. Our assumption is that, because our volunteers
received most of the malicious emails directly, they were
likely to recognize cases where their contacts were be-
ing impersonated. We note that labeling is conservative:
Our volunteers may sometimes label Spoofed or Typo ad-
dresses as Unknown because they do not know the person
impersonated in the attack. This may happen, for exam-
ple, in cases where they were not the primary target of
the attack (e.g., they appeared in Cc).
Limitations. Our dataset originates from WUC and is
limited to those victims that were targeted together with
that organization. We will see that these victims were of-
ten NGOs. As a result, the social engineering techniques
observed here may differ from attacks against different
entities such as companies, political institutions, or even
other NGOs. Despite these limitations, we argue that this
analysis is an important ﬁrst step towards understanding
the human factors exploited by targeted attacks.

3.2 Results
In this subsection, we discuss the results of our analy-
sis of the social engineering techniques used in the mali-
cious emails.
Topics and language. The topic of malicious emails in
our dataset can generally be classiﬁed into one of three
categories: WUC, Uyghur, and human-rights. In partic-
ular, we observed 51% (575) of malicious emails per-
taining to WUC, 29% (326) to Uyghurs, 12% (139) to
human-rights, and 3% (28) to other topics. In addition,
the native language of the victim is often used in the ma-
licious emails. In fact, 69% (664) of the emails sent to the
second volunteer were written in the Uyghur language,
and 62% (96) for the ﬁrst one. These results indicate that
attackers invested signiﬁcant effort to tailor the content
of the malicious emails to their victims, as we see in Fig-
ure 2 and Figure 3.
Specialized events.
In addition to being on topic, we
also observed that emails often referred to speciﬁc events
that would only be of interest to the targeted victims.
Throughout our dataset, we found 46% of events (491)
related to organizational events (e.g., conferences). We
note that these references are generally much more spe-
cialized than those used in typical phishing and other
proﬁt-motivated attacks. For example, Figure 1 shows a
screenshot of an attack that replayed the announcement
of a conference on a very specialized topic. The mali-
cious email was edited by the attacker to add that all fees
would be covered (probably to raise the target’s interest).
Impersonation. We ﬁnd that attackers used carefully
crafted email addresses to impersonate high-proﬁle iden-
tities that the victims may directly know. That is, attack-
ers used one of the following four techniques to add le-
gitimacy to a malicious email: First, 41% (465) of the

Figure 2: Distribution of the topics of the malicious
emails for each year of the dataset shared by our two
volunteers. The left bar corresponds to the data shared
by both volunteers, and the next two bar groups to each
year of the data shared by our ﬁrst and second volun-
teer, respectively. The content of malicious emails is
targeted to the victims.

Figure 3: Distribution of languages for each year of our
dataset. Malicious emails employ the language of their
victims.

Impersonation. Finally, to understand the social con-
text of the attack, each of our volunteers coded (based
on her experience within the organization) all the email
addresses of the senders into one of ﬁve categories:
Spoofed, Typo, Name, Suspicious, or Unknown. (Coding
was done based exclusively on the personal knowledge
of the volunteers.) An email is marked as Spoofed if it
bears the exact sender email address of a person known
to our volunteers, as Typo if it resembles a sender email
address known to the receiver but is not identical, and as
Name if the attacker used the full name of a volunteer’s
contact (with a different email address). Finally, email
addresses that look as if they had been generated by
a computer program (e.g., uiow839djs93j@yahoo.com)
are labeled as Suspicious and all remaining emails as Un-

5

Topics of malicious emails

194

292

259

20

2

10

134
5

32

37

87
3
3

17

33

14
9

28

67

35

74

171

 

130
4
8

42

15

17

63

156

76

Unknown
Other
Human rights
Uyghur
WUC

1116
48

139

326

575

s

l
i

a
m
e

 
s
u
o
c

i

i
l

a
m

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

8

57

31

76

All

2012 2013

2009 2010 2011 2012 2013

Years

s

l
i

a
m
e

 
s
u
o
c

i

i
l

a
m

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

1116

52

760

267

All

Languages of malicious emails

20

2

7

11

134

87

194

292

259

130

 

8
4

9

34

18

18

104

198

32

66

216

112

Unknown
Other
Chinese
Uyghur
English

68

35

13

89

42

2012 2013

2009 2010 2011 2012 2013

Years

Figure 4: Distribution of senders’ impersonation tech-
niques for each year of our dataset. Malicious emails
spoof the email address of a contact of the volunteers,
use a very similar address controlled by the attacker,
or a contact’s full name.

email addresses have Typos (i.e., the email address re-
sembles known sender addresses, but with minor, sub-
tle differences). These email addresses are identical to
legitimate ones with the exception of a few characters
being swapped, replaced, or added in the username. Sec-
ond, 12% (134) of the senders’ full names corresponded
to existing contacts of the volunteers. Third, we ﬁnd
that most email addresses belonged to well-known email
providers — Google being the most prominent with 58%
of all emails using the Gmail or GoogleMail domains,
followed by Yahoo with 16%.

Fourth, we ﬁnd that 30% (337) of the sender emails
were spoofed (i.e., the email was sent from the address of
a person that the volunteer knows). This observation sug-
gests that the attacker had knowledge of the victim’s so-
cial context, and had either spoofed the email header, or
compromised the corresponding email account. To iden-
tify a subset of compromised email accounts, we con-
sider spoofed emails authenticated by the senders’ do-
mains using both SPF and DKIM. To reduce the chances
of capturing compromised servers instead of compro-
mised accounts, we also consider only well-known, trust-
worthy domains such as GMail. This procedure yields
malicious emails that were likely sent from the legitimate
account of the victims’ contacts. We found that three
email accounts belonging to prominent activists, includ-
ing two out of 10 of the WUC leaders, were compro-
mised and being used to send malicious emails. We have
alerted these users and are currently working with them
to deploy defenses and more comprehensive monitoring
techniques, as we will discuss in Section 6.

We show the distributions of malicious emails sent
with spoofed, typo, suspicious, or unknown email ad-
dresses in Figure 4, and the ranks of the impersonated

Figure 5: Distribution of impersonated senders’ ranks for
each year of our dataset. Malicious emails often imper-
sonate high-proﬁle individuals.

Figure 6: Distribution of languages employed to write
about the main topics of malicious emails. There is a
strong correlation between malicious emails’ topics
and the language in which they are written.

senders in Figure 5. (We do not show the correspond-
ing ranks for receivers because NGOs generally function
with a handful of employees, all playing a key role in the
organization.)
Targeted victims. For the analysis below, which lever-
ages other recipients besides our two volunteers, we fur-
ther ﬁlter emails to keep only those originating from
well-known domains (as described in Section 2). Doing
this leaves us with 568 malicious emails that are likely
to have indeed been sent to all the email addresses in the
header. We ﬁnd that the attacks target more organiza-
tions than WUC, including 38 Uyghur NGOs, 28 Other
NGOs, as well as 41 Journalistic, Academic, and Polit-
ical organizations.
(See Appendix A for the complete
list of targeted organizations.)
Interestingly, we ﬁnd a
strong correlation between the topic of an email and the
language in which the email was written, as we show in
Figure 6. Our results show that English was more and

6

s

l
i

a
m
e

 
s
u
o
c

i

i
l

a
m

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

1116

173

134

465

337

All

Impersonation techniques

20

134

87

194

292

259

130

 

13

9

3

6

11

88

Unknown
Suspicious
Name
Typo
Spoofed

23

2012 2013

34

31

89

136

36

30

115

76

48

26

58

61

15

11

87

17

27

24

22

13

2009 2010 2011 2012 2013

Years

s

l
i

a
m
e

 
s
u
o
c

i

i
l

a
m

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

Ranks of impersonated senders

1116

173

71

150

722

134

13
5

25

91

20

1

8

11

87

194

292

259

130

 

34

22

46

190

27

8

11

48

21

33

41

92

36

12
14

15

13

197

100

Unknown
Low
Medium
High

All

2012 2013

2009 2010 2011 2012 2013

Years

Correlation between topics and languages

 

s

l
i

a
m
e

 
s
u
o
c

i

i
l

a
m

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

1116

52

760

267

All

575

515

39

WUC

326

23

183

113

139

6

19

16

28
1
1
2

6

48

4

40

95

18

Unknown
Other
Chinese
Uyghur
English

2

Uyghur Rights Others Unknown
Topics

Summary of Findings. We now revisit the initial ques-
tions posed at the beginning of this section. First, we
saw that most emails in our dataset pertained to WUC,
Uyghurs, or human-rights, were written in the recipi-
ent’s mother tongue, and often referred to very special-
ized events. We also found that sender impersonation
was common and that some email accounts belonging to
WUC’s leadership were compromised and used to spread
targeted attacks. (We note that many more accounts may
be compromised but remain dormant or do not appear
as compromised in our dataset.) Second, we showed
that numerous NGOs were being targeted simultaneously
with WUC and that the specialization of emails var-
ied depending on the recipient(s). Finally, we observed
that the most targeted victims received several malicious
emails every month and that attacks were sprayed over
several organizations’ employees.

4 Analysis of attack vectors

We now analyze the techniques used to execute arbitrary
code on the victim’s computer. The related work re-
ports the use of malicious links, email attachments, and
IP tracking services [10, 16]. Whereas ISTR 2013 re-
ports that EXE are largely used in targeted attacks, and
the Mandiant report that ZIP is the predominant format
that they have observed in the last several years, we ﬁnd
that these formats represent 0% and 4% (49) of malicious
attachments in our dataset, respectively. Instead, we ﬁnd
RAR archives and malicious documents to be the most
common attack vectors. Hypotheses that may explain
these discrepancies with the Mandiant report include the
tuning of attack vectors to adapt to the defenses mecha-
nisms used by different populations of email users (e.g.,
NGOs vs. corporations); Mandiant’s attacker (APT1),
mainly using primitive attack vectors such as archives;
and/or Mandiant having excluded more advanced attack
vectors, such as documents, from its report. However, in
the absence of empirical data on APT1’s attack vectors,
we cannot test these hypotheses. In this section, we per-
form a quantitative study of the attack vectors employed
in our dataset, and also analyze their dynamics. We seek
to answer the following questions:

(cid:15) What attack vectors are being employed against
WUC? Do they generally rely only on human fail-
ures or also on software vulnerabilities? Do they
evolve in time and if so, how quickly do they adapt
to new defense mechanisms?

(cid:15) What is the efﬁcacy of existing countermeasures?
As all malicious documents in our dataset used
well-known vulnerabilities, would commercial,
state-of-the-art defenses have detected all of them?

Figure 7: Timeline of attacks, in number of malicious
emails per month, against the 60 most targeted victims
(our two volunteers’ rows are shaded and the vertical
line corresponds to one of our volunteer joining WUC).
The Y axis represents victims grouped by organization.
ETUE corresponds to the East Turkestan Union in Eu-
rope NGO and Others to different organizations. Each of
the top 60 victims has been frequently attacked over
the last four years and several victims from the same
NGOs were attacked simultaneously.

more common as the topic became less and less special-
ized. We hypothesize that attackers may have sent the
same email messages to several recipients with similar
interests to reduce the costs involved in manually craft-
ing these emails.
Timing. Our dataset shows that the same victims were
frequently targeted and that several members of the
same organization were routinely targeted simultane-
ously. This suggests that attackers were using a “spray”
strategy, trying to ﬁnd the weakest links in the targeted
organization, and hence, optimizing their chance of suc-
cess. Spraying is clearly visible in Figure 7 where we
see that the top 60 most targeted victims in our dataset
received malicious emails often over the last four years.
(We note that the dataset shared by one of our volun-
teers starts on August 2012, explaining why we observe
more malicious emails after that date.) We also see that,
31 email accounts from individuals without afﬁliation to
WUC were often targeted simultaneously to the WUC
accounts.

7

Figure 8: Number of malicious documents containing a given vulnerability (CVE) (left) and target application (right)
for each month of our dataset. We represent the top four CVEs in number of attacks over the whole trace individu-
ally and others are represented in aggregate. The vertical line in November 2010 corresponds to the deployment of
sandboxing in Acrobat Reader. Although Acrobat Reader was the most targeted application until 2010, recent
attacks mainly target the Ofﬁce suite.
4.1 Methodology
Malicious archives. To analyze the archives’ contents,
we extracted them in a disconnected VM environment
and manually inspected their contents to determine the
type of ﬁles they contain, independently of their exten-
sions. In the case of EXE ﬁles, we also examined them
manually to determine whether their Microsoft Windows
icons were similar to those used for other ﬁle formats
(e.g., JPEG) in order to persuade average users that they
were not executable.
Malicious documents. We used two methodologies to
determine the characteristics of the vulnerabilities being
exploited by malicious documents. First, we submitted
the documents to VirusTotal [1] for analysis. Each of the
45 Antivirus (AVs) on VirusTotal classiﬁed the checked
sample as benign or malicious, and attached a “tag” de-
scribing the auxiliary information relating to the sample.
Often the tag is a Common Vulnerabilities and Exposures
(CVE) number, presumably corresponding to the signa-
ture that matched, but in some cases, the tag ﬁeld is not
a CVE; it is either tagged as “unknown” or contains a
symptomatic description such as the inclusion of a sus-
picious OLE object. We refer to these three tags as CVE,
Unknown, and Heuristic, respectively. Often all AVs re-
ported a Single CVE but sometimes, they reported Mul-
tiple, conﬂicting CVEs. Once we collected all CVE tags,
we then scraped the National Vulnerability Database [18]
to obtain the release date and vulnerable applications for
each of the CVEs that we found.

our taint-assisted manual analysis are described in Ap-
pendix B.
Defenses. We performed a retrospective analysis of the
protection offered by common defenses such as AV and
webmail providers in the context of our malicious docu-
ments. For AV, we used VirusTotal to determine whether
a malicious document is detected by the scanning engine
of each AV, as described above. For webmail channels,
we created an email account on GMail, Hotmail, and Ya-
hoo, and used a dedicated SMTP server to send emails
to that account with malicious documents attached. We
considered malicious documents delivered without mod-
iﬁcations as undetected by the webmail defenses. Oth-
erwise, if an email or its attachment is dropped, or if the
attachment’s payload is modiﬁed, we considered it as de-
tected. The analyses based on webmails and VirusTotal
were performed in November 2013 and July 2014, re-
spectively.
Limitations. As with social engineering, our analysis
of attack vectors is biased towards NGOs. In addition,
the above methodology is limited to the attack vectors
captured in our dataset. For example, we miss attacks
against the NGOs’ web servers unless the corresponding
malicious link appears in the suspicious emails.

Second, our taint-assisted analysis of vulnerabilities is
limited to those documents for which we were able to
analyze the logs manually. For example, we found that
opening PDF ﬁles in our environment generated log ﬁles
that were far too large (around 15GB in the median case)
for manual analysis. As a result, we were able to man-
ually conﬁrm vulnerabilities only against Microsoft Of-
ﬁce. However, despite this limitation, we were also able
to determine which PDF documents contained malware
through manual inspection.

Second, we inspected the documents manually to con-
ﬁrm that they contain malware, and also used taint-
assisted analysis both to verify the accuracy of the CVEs
reported in AV reports and to investigate the presence of
zero-day vulnerabilities.1 The methodological details of

1Hereafter, zero-day vulnerabilities refer to vulnerabilities that were

not publicly disclosed at the time of the attack.

8

Targeted vulnerabilities

 

Unknown 
Others 
2006−2492 
2009−3129 
2010−3333 
2012−0158 

60

50

40

30

20

10

s
t

n
e
m
u
c
o
d

 
s
u
o
c

i

i
l

a
m

 
f

o

 
r
e
b
m
u
N

 

0
2009−09

2010−09

2011−09

Time

2012−09

2013−09

Targeted applications

 

Office
Acrobat

60

50

40

30

20

10

s
t

n
e
m
u
c
o
d

 
s
u
o
c

i

i
l

a
m

 
f

o

 
r
e
b
m
u
N

 

0
2009−09

2010−09

2011−09

Time

2012−09

2013−09

Table 2: List of well-known vulnerabilities exploited by
malicious documents. Release corresponds to the release
date of the vulnerability and First to its ﬁrst exploitation
in our data set (in number of days relative to the release
date). Resolved corresponds to the number of Microsoft
Ofﬁce vulnerabilities that were mistagged in AV reports
but that we were able to resolve using taint-assisted man-
ual analysis.

CVE

Release First

Apps
2006-0022 06/13/06 1,191 Ofﬁce
2006-2389 07/11/06 1,166 Ofﬁce
2006-2492 05/20/06 1,125 Ofﬁce
588 Acrobat
2007-5659 02/12/08
2008-0081 01/16/08
651 Ofﬁce
2008-0118 03/11/08 1,010 Ofﬁce
824 Ofﬁce
2008-4841 12/10/08
405 Ofﬁce
2009-0557 06/10/09
880 Ofﬁce
2009-0563 06/10/09
2009-0927 03/19/09
180 Acrobat
68 Acrobat
2009-1862 07/23/09
188 Ofﬁce
2009-3129 11/11/09
4
2009-4324 12/15/09
Acrobat
2010-0188 02/22/10
28 Acrobat
Acrobat
0
2010-1297 06/08/10
Acrobat
7
2010-2883 09/09/10
Ofﬁce
49
2010-3333 11/10/10
0
2010-3654 10/29/10
Ofﬁce
2011-0611 04/13/11
0
Acrobat
224 Ofﬁce
2011-0097 04/13/11
Acrobat
2
2011-2462 12/07/11
37
2012-0158 04/10/12
Ofﬁce
2013-0640 02/14/13
68 Acrobat

# emails Resolved

2
18
59
3
1
1
1
2
31
11
3
58
15
15
9
7
220
7
19
3
5
278
1

0
16
47
0
0
0
0
0
0
0
0
4
0
0
0
0
0
0
0
0
0
12
0

Finally, our defense analysis was performed in bulk,
after the time of the attacks. As a result of the difference
between the times of attack and analysis (up to four years
for the ﬁrst malicious documents), the detection rates re-
ported hereafter should be treated as upper bounds. This
is because the AV signatures at the time of the analysis
were more up-to-date than they would have been at the
time of the attack.
4.2 Results: Attack vectors
4.2.1 Malicious archives

We observed numerous targeted attacks leveraging social
engineering and human failure to install malware on the
victim’s computer. In particular, we found 247 RAR and
49 ZIP containing malicious EXE. In 10 cases, the ma-
licious archives were password protected with the pass-
word included in the email’s body. We hypothesize that
archiving was used as a rudimentary form of packer for
the malware to evade detection by the distribution chan-
nels. Finally, we found that 20% of all EXEs contained
in the archives used an icon that resembled a non-EXE,
i.e., a DOC, JPEG, or PDF icon, in 20%, 19%, and 7%
of the cases.

9

Figure 9: Timeline of the target vulnerabilities. The Y
axis corresponds to CVEs and each circle to the number
of CVEs seen each month after the public disclosure of
the vulnerability (day 0). All vulnerabilities were ﬁrst
targeted after their public disclosure.

4.2.2 Malicious documents

We used taint-assisted analysis to resolve the conﬂicts
due to AV mistagging and summarize the CVE informa-
tion in Table 2. The number of conﬂicts resolved using
taint-assisted manual analysis is reported in the last col-
umn Resolved. Additional taint-analysis results are re-
ported in Appendix B.
Zero-day versus unpatched vulnerabilities. We ﬁnd
no evidence of the use of zero-day vulnerabilities against
our dataset, but several uses of disclosed vulnerabilities
within the same week as their public release date.
In
addition, we see in Figure 9 that vulnerabilities continued
to be exploited for years after their disclosure, and this
conﬁrms that unpatched vulnerabilities represent a large
fraction of attacks in our dataset. To ascertain the CVE
being exploited in each sample, we used a combination
of the telemetry data available in CVE tags generated by
AVs, and a manual analysis to resolve cases where the tag
was ambiguous. For each sample, we then recover the
public disclosure date for the vulnerability manually, and
treat it as the corresponding day-zero. By comparing the
time of use in our email dataset, we are able to ascertain
the lifetime of vulnerability exploits.

We ﬁnd several instances of exploits that were used
in publicly-reported targeted attacks in our dataset. For

2006−0022
2006−2389
2006−2492
2008−0118
2009−0563
2008−4841
2008−0081
2007−5659
2009−0557
2011−0097
2009−3129
2009−0927
2013−0640
2009−1862
2010−3333
2012−0158
2010−0188
2010−2883
2009−4324
2011−2462
2011−0611
2010−3654

 

day 0

 

1

2
3
Time (years)

4

5

1−5
Acrobat

6−10
Office

>10

Figure 10: Detection rates of popular webmails for the
malicious documents. The efﬁcacy of webmails to de-
tect malicious documents varies widely.

instance, vulnerabilities such as CVE-2009-4324, CVE-
2010-3654, and CVE-2010-2883 have been reported to
be zero-day vulnerabilities [6]. However, in our dataset,
these vulnerabilities were used after their disclosure.
Evolution of target applications. Our data shows a
sudden switch from Adobe Reader to Microsoft Ofﬁce
suite as the primary targeted application as of Novem-
ber 2010, as seen in Figure 8. We ﬁnd a correlation be-
tween the time of this switch and two events: (a) the de-
ployment of sandboxing defenses in Adobe Reader and
(b) the disclosure of vulnerabilities in the Ofﬁce suite.
The ﬁrst version of Acrobat Reader to support sandbox-
ing for Windows (version 10.0) was released on Novem-
ber 15, 2010. Within the same month, a stack buffer
overﬂow against Microsoft Ofﬁce was released publicly
(November 2010), reported as CVE-2010-3333. We see
this CVE being massively exploited in our dataset as of
January 2011, which is a time lag of two months. We
observe the use of CVE-2010-3333 being replaced with
CVE-2012-0158 in January 2013. This evidence sug-
gests that attackers adapted their targeted vectors to use
newly disclosed vulnerabilities within a few days to a few
months of disclosure, and that updates to the security de-
sign of software reduces its exploitability in the wild (as
one would expect).

4.3 Results: Bypassing common defenses

We now investigate the efﬁcacy of existing defenses
against malicious documents.
Email / Webmail Filtering. Despite the retrospective
analysis of the malicious documents, we ﬁnd that the
detection rates of malicious documents for GMail, Hot-
mail, and Yahoo were still relatively low (see Figure 10).
We also ﬁnd that GMail failed to detect most malicious
documents sent after March 2012. In particular, while
the detection of documents sent before March 2012 was

Figure 11: Detection rates of malicious documents for
each of the top 30 AVs as reported by VirusTotal. No sin-
gle AV detected all malicious documents despite their
use of well-known vulnerabilities.

73%, it is 28% after that date. Interestingly, 71% of the
true positives for GMail after March 2012 corresponded
to RTF ﬁles with all nrnn character sequences substituted
with the nn character. While this substitution did not de-
activate the malware, we observed that it broke the shell-
codes embedded into these documents as they require the
document size to remain unchanged to function properly.
As a result, the malware was never executed. Although
we cannot verify the purpose of this substitution, we note
that its appearance coincided with that of the malicious
RTF ﬁles. We conclude this discussion by pointing out
that Yahoo’s low detection rate is interesting as it claims
to be using Symantec AV for its webmail service [12] —
which, as we will see below, has a much higher detection
rate.
Signature-based AV Scanning. In Figure 11, we show
the detection rates for the top 30 VirusTotal AVs, sorted
by decreasing detection rate of the malicious documents.
There are two main takeaways from this graph. First,
no single vendor detected all original malicious docu-
ments, even though we have seen that they used well-
known vulnerabilities. For example, Qihoo, the vendor
with the overall best efﬁcacy, was unable to detect 3% of
the malicious documents based on scanning. Second, we
observe large variations among the efﬁcacy of different
AV vendors. That is, the detection rate dropped by 30%
from the ﬁrst to the twentieth AV (CAT QuickHeal) and
the 15 AVs with the lowest detection rate (not shown) all
had a detection rate of less than 35%.
Summary of Findings. We found that malicious docu-
ments are the most popular attack vectors in our dataset
followed by malicious archives. Malicious documents
tended to use newly released vulnerabilities, often within

10

e
t
a
r
 
n
o
i
t
c
e
t
e
D

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

GMail

Hotmail

Yahoo!

e
t
a
r
 
n
o
i
t
c
e
t
e
D

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

C AT− Q uickHeal
Trend Micro
Trend Micro−HouseCall
AV G
Antiy−AVL
Avast
Ad−A ware
M cAfee− G W −Edition
BitDefender
DrW eb
M cAfee
Bkav
Micro W orld−eScan
Co m mtouch
G Data
Microsoft
ESET−N O D32
nProtect
AntiVir
Sophos
Qihoo−360
E m sisoft
Sym antec
F−Secure
Kaspersky
Fortinet
Ikarus
N A N O −Antivirus
Norm an

VIP R E

Table 3: Summary of the malware clusters. For each cluster, we show the malware family (or an ID if we could
not determine it), the number of malicious emails containing the malware, the number of Command and Control
(C2) servers, the similarities in terms of communication protocols and C2 with malware attributed to known entities
(entity(Com,C2)). Our dataset contains several families of ﬁrst-stage malware previously seen in targeted attacks
carried out in the wild.

Clusters
# samples

# C2

Similarity DTL(C2)

1

2

67 (9%)

6

58 (8%)

2
—

Surtr
51 (7%)

6

DTL(C2)

4

5

6

7

8

9

37 (5%)

18
—

30 (4%)

13
—

22 (3%)

3
—

19 (2%)

8
—

19 (2%)

13
—

18 (2%)

9
—

TravNet
13 (2%)

4

TravNet(Com,C2)

a week, continued to utilize them for several years, and
most of them used well-known instead of zero-day vul-
nerabilities. In particular, our taint-assisted manual anal-
ysis of Ofﬁce documents did not reveal a single zero-
day vulnerability in our dataset. This raises the ques-
tion of whether defense mechanisms deployed in web-
mails and state-of-the-art commercial defenses are effec-
tive in blocking these well-known attacks. Furthermore,
we found that malicious archives often contained EXE
ﬁles that masquerade as pictures or documents.

5 Malware analysis

We now analyze the ﬁrst-stage malware found in ma-
licious documents. Unlike the Mandiant report, which
provides an analysis for malware that targets different
organizations and that (they claim) originates from the
same group, our analysis focuses on all malware (in our
dataset) that has targeted a single organization. By look-
ing at targeted attacks from the perspective of the target
rather than the attacker, our analysis enables us to de-
termine whether WUC has been targeted with the same
or different malware over the years. We also take a dif-
ferent approach from the authors of the GhostNet report
who performed malware analysis on a few compromised
systems belonging to different but related organizations.
We instead analyze over six hundred malware samples
used to establish a foothold on the targeted systems of a
single organization. Our analysis differs from the related
work in its scale and context [16] or focus [10]. This
section aims to answer the following question:

(cid:15) Is WUC targeted with the same or different mal-
ware? In the latter case, are there similarities be-
tween this ﬁrst-stage malware and others found in
targeted attacks in the wild?

5.1 Methodology
Our analysis below was done on 689 malware samples
that we extracted from malicious documents.
Clustering. To make our analysis tractable for 689
malware samples, we started by clustering the malware

based on its behavior. To do so, we ran the malicious
EXE and DLL ﬁles in a disconnected sandboxed envi-
ronment and hooked the function calls to resolve domain
names and establish network communications.
In ad-
dition, to obtain the TCP port number on which com-
munication is done, we intercepted function calls to
gethostbyname and returned a dummy routable IP ad-
dress. As a result, the malware subsequently reveals the
port number when it initiates a connection with the re-
turned IP. (See Appendix C for the complete list of Com-
mand and Control (C2) domains.) Finally, we generated
behavioral proﬁles for 586 samples, clustered them using
an approach similar to [5, 14], and manually veriﬁed the
accuracy of the resulting clusters.
Malware family and similarities. Similarly to Bailey
et al. [5], we found that determining the malware fam-
ily using AV signature scanning was unproductive. To
determine whether our malware shares similarities with
other known targeted malware, we relied on several re-
ports on targeted attacks [9,13]. We extracted the C2 do-
mains and, when available, additional information about
the malware (e.g., hashes and behavior) from these re-
ports. Finally, we correlated the domains, IP addresses,
hashes, and behavioral proﬁles with those from the re-
ports in order to ﬁnd similarities between the different
sets of malware. We performed this analysis in February
2014.
Limitations. Our behavioral analysis was performed in a
disconnected environment and as a result, it is limited to
the ﬁrst stage of the malware behavior. Studying the be-
havior of additional payload that would be downloaded
after the compromise is beyond the scope of this paper
and will be the subject of future work.

5.2 Results
We now analyze the malware clusters and their similari-
ties with other targeted malware found in the wild.
Cluster sizes. We ﬁnd that 57% of our malware be-
longed to the ten largest clusters (we show additional
information about these clusters in Table 3).
In total,
ﬁve clusters (two in the top ten) used at least one of
dtl6.mooo.com, dtl.dnsd.me, or dtl.eatuo.com as their

11

C2 domains, indicating some operational link between
them.
In fact, at the time of analysis, these three do-
mains resolved into the same IP address and the mal-
ware in each cluster connected to different ports of the
same server. Despite these apparent similarities, how-
ever, manual analysis of the behavioral logs revealed that
their logic differed from one another, explaining their as-
signment to different clusters. Combined, these ﬁve clus-
ters represented 24% of the malware that we analyzed.

Malware family and similarities. We found various de-
grees of similarities between our clusters and targeted at-
tacks reported in the wild. First, the ﬁve clusters above
had the same C2 as the DTL group reported by FireEye
in November 2013 and that the malware was of the same
family as one of these clusters’ (APT.9002, not shown)
[9]. In particular, we found that one of our samples in
that cluster had the same MD5 hash as those described
in the FireEye report and that eight had identical mani-
fest resources. FireEye claims that this malware has been
used in targeted attacks against various governmental and
industrial organizations.

Second, malware in the Surtr cluster had the same be-
havioral proﬁle as samples used against the Tibetan com-
munity in March 2012 [7]. Although the two sets of sam-
ples had different MD5 hashes, they both connected to
the same C2 server (shared with APT.9002) on the same
port number, and exhibited the same behavior to estab-
lish persistency on the victim’s machine.

Third, our 13 TravNet samples exhibited similar be-
havior as those used against Indian targets in 2013 [2]. To
do so, we obtained the samples used in India, generated
their behavioral proﬁles, and compared them manually
with the malware in our TravNet cluster. Although both
sets connected to different C2 servers and exhibited vari-
ations in the way they searched the victims’ ﬁle system,
we found that they both used the same communication
protocol with the C2.

Fourth, samples in another cluster communicated with
the same C2 server and exhibited the same behavior as a
Vidgrab sample found in a malicious document sent to a
victim in Hong Kong in August 2013 [8].

Summary of ﬁndings. We found that WUC has been
targeted with several malware families in the last year.
We also showed that the Surtr and APT.9002 clusters
corresponded to malware that Citizenlab and FireEye
identiﬁed as having targeted the Tibetan community,
as well as other political and industrial organizations
[7, 9]. Furthermore, 24% of our malware (including
Surtr, APT.9002 and three other clusters) had at least one
C2 domain in common, which was identical to those of
the Citizenlab and FireEye reports.

6 Future Work

Several directions for future work arise from this work.
We brieﬂy discuss them below.
Attack vectors and generalization. Our analysis is
limited to attack vectors used against WUC. Similar stud-
ies on a wider range of targets would beneﬁt understand-
ing this emerging threat better. Further, our attack vec-
tors distributed over email channels and have two main
limitations. First, it is possible that our volunteers have
been attacked via other channels besides email. Sec-
ond, although we have seen various organizations tar-
geted with the same malware as WUC, it is generally
hard to determine with certainty which victims were the
primary target of these attacks. Therefore, it is possi-
ble that other victims have been targeted with additional
attack vectors when the attacks did not involve WUC.
Further research is needed to overcome these limitations
Exploring different channels that attackers use for dis-
tributing malicious payloads is important. As a step to-
wards this goal, we are currently collaborating with the
Safebrowsing team at Google to investigate the emer-
gent threat of watering-hole attacks. These attacks are
conceptually very similar to drive-by download attacks
with one key difference: They compromise very speciﬁc
websites commonly visited by the targeted community
(e.g., a company’s website) and wait for victims to visit
the website. As compared to spear phishing, watering-
hole attacks offer the advantage of potentially targeting
a fairly large number of victims (e.g., all employees of a
large company) before raising suspicion. We conjecture
that the small number of suspicious links in our dataset
may be due to the small size of the targeted organizations
and the public availability of their employees’ email ad-
dresses.

Other attack vectors include but are not limited to
packets injection to redirect victims to malicious servers
(similar to those used in watering-hole attacks) and phys-
ical attacks on the victims’ devices [3]. Detecting these
attacks would require completely different methodolo-
gies than the one we used in this paper.
Monitoring. We have seen that a few high-proﬁle mem-
bers of the Uyghur community were compromised and
that their email accounts were being used as stepping
stones to carry out targeted attacks. Although it is possi-
ble that these email accounts were compromised via tar-
geted attacks, we have not yet conﬁrmed this hypothesis.
More generally, we do not know yet what is the speciﬁc
aim of these targeted attacks. Monitoring the full lifecy-
cle of targeted attacks would require novel measurement
systems, deployed at the end users, that can identify com-
promises without being detected.

Pinpointing the geolocation of attackers carrying out
targeted attacks, or attack attribution, is another open

12

monitoring challenge. Marczak et al. were able to at-
tribute targeted attacks to governments in the Middle
East by analyzing relationships of cause and effect be-
tween compromises and real-world consequences [16].
In contrast to monitoring and attack attribution, this pa-
per has presented a extensive, complementary analysis of
the life cycle of targeted attacks before the compromise.
Large-scale malware analysis and clustering. We
found it challenging to (a) cluster targeted malware and
(b) locate similar samples. First, this malware sometimes
exhibits signiﬁcant similarity in its logic and different
malware may also use the same Command and Control
(C2) infrastructure. As a result, traditional clustering al-
gorithms tend not to work very well. Second, we located
similar samples based on a limited set of indicators such
as C2, cryptographic hash, or YARA signatures, how-
ever, we feel that our current capability in that respect has
a lot of room for improvement. We foresee that a search
engine that can, for example, locate malware matching
certain indicators out of an arbitrarily large corpus would
be a useful instrument for researchers working on tar-
geted attacks.

Our analysis of CVEs highlights that telemetry data
from commercial AVs is not always reliable. Our analy-
sis complemented with taint-analysis was largely manual
and time-intensive. Analysis techniques to quickly diag-
nose known CVEs directly from given exploits is an open
problem and perhaps one of independent interest.
Defenses. Our ﬁndings conﬁrm that AVs may miss
known CVEs, even years after their release dates.
Clearly, known CVEs contribute a large part of the
emerging threat of targeted attacks. Understanding why
commercial AVs miss known attacks conclusively, for
example to tradeoff false positives or performance for
security, is an important research direction. Designing
effective defenses against targeted attacks is a major re-
search challenge which depends on our ability to under-
stand the threat at hand. As part of future work, one
could evaluate the effectiveness of novel defenses based
on the ﬁndings from this paper. As a small step towards
that goal, we plan to soon deploy a webmail plugin that
combines metadata and stylometry analysis [17] to detect
contact impersonation.

7 Conclusion

We have presented an empirical analysis of a dataset
capturing four years of targeted attacks against a human-
rights NGO. First, we showed that social engineering
was an important component of targeted attacks with
signiﬁcant effort paid in crafting emails that look legiti-
mate in terms of topics, languages, and senders. We also
found that victims were targeted often, over the course
of several years, and simultaneously with colleagues

from the same organization. Second, we found that
malicious documents with well-known vulnerabilities
were the most common attack vectors in our dataset and
that they tended to bypass common defenses deployed in
webmails or users’ computers. Finally, we provided an
analysis of the targeted malware and showed that over
a quarter of samples exhibited similarities with entities
known to be involved in targeted attacks against a variety
of industries. We hope that this paper, together with
the public release of our malware dataset, will facilitate
future research on targeted attacks and, ultimately, guide
the deployment of effective defenses against this threat.

Acknowledgements. The authors would like to thank
the anonymous reviewers, our shepherd Stuart Schechter,
and Peter Druschel for their useful feedback. We would
also like to acknowledge Karmina Aquino (F-Secure),
Emiliano Martinez (VirusTotal), Mila Parkour (Conta-
gio), and Nart Villeuneuve (FireEye) for their help locat-
ing similar malicious documents. Finally, we thank the
Max Planck Society, the Ministry of Education of Singa-
pore under Grant No. R-252-000-495-133, and the NSF
under Grant No. CNS-1116777 for partially supporting
this work.

References

[1] http://www.virustotal.com.
APT
[2] Inside
Tech.

report

space.

ber
content/uploads/2013/downloads/Inside Report by Infosec
Consortium.pdf.

attacks
rep.

indian

on
cy-
http://g0s.org/wp-

[3] Inside TAO: Documents reveal top nsa hacking unit.

http://www.spiegel.de/international/world/the-nsa-uses-
powerful-toolbox-in-effort-to-spy-on-global-networks-a-
940969.html.

[4] The Slingshot Project. http://slingshot.mpi-sws.org.
[5] BAILEY, M., ANDERSEN, J., MORLEYMAO, Z., AND
JAHANIAN, F. Automated classiﬁcation and analysis of
internet malware. In Proceedings of Recent Advances in
Intrusion Detection (RAID 2007).

[6] BILGE, L., AND DUMITRAS, T. Before we knew it: An
empirical study of zero-day attacks in the real world. In
Proceedings of the 2012 ACM conference on Computer
and communications security (CCS 2012) (2012).

[7] CITIZEN LAB.

Surtr: Malware
community.

family tar-
rep.
Tech.

the

tibetan

geting
https://citizenlab.org/2013/08/surtr-malware-family-
targeting-the-tibetan-community/.

[8] CONTAGIO. http://contagiodump.blogspot.de/2013/09/

sandbox-miming-cve-2012-0158-in-mhtml.html.

[9] FIREEYE. Supply chain analysis: From quartermaster to

sunshop. Tech. rep.

13

[10] HARDY, S., CRETE-NISHIHATA, M., KLEEMOLA, K.,
SENFT, A., SONNE, B., WISEMAN, G., AND GILL,
P. Targeted threat index: Characterizing and quantifying
politically-motivated targeted malware. In Proceedings of
the 23rd USENIX Security Symposium (San Diego, CA).
[11] INFORMATION WARFARE MONITOR. Tracking ghost-
net: Investigating a cyber espionage network. Tech. rep.,
2009.

[12] JANA, S., AND SHMATIKOV, V. Abusing ﬁle processing
in malware detectors for fun and proﬁt. In Proceedings
of the 33rd IEEE Symposium on Security & Privacy (San
Francisco, CA).

[13] KASPERSKY. The nettraveler (aka TravNeT). Tech. rep.

https://www.securelist.com/en/downloads/vlpdfs/kaspersky-
the-net-traveler-part1-ﬁnal.pdf.

[14] KRUEGEL, C., KIRDA, E., COMPARETTI, P. M.,
BAYER, U., AND HLAUSCHEK, C. Scalable, behavior-
In Proceedings of the 16th
based malware clustering.
Annual Network and Distributed System Security Sympo-
sium (NDSS 2009) (2009).
APT1

[15] MANDIANT.

exposing

one

of
rep.,

chi-
2013.

nas cyber espionage units.
http://intelreport.mandiant.com/.

Tech.

[16] MARCZAK, W. R., SCOTT-RAILTON, J., MARQUIS-
BOIRE, M., AND PAXSON, V. When governments hack
opponents: A look at actors and technology. In Proceed-
ings of the 23rd USENIX Security Symposium (San Diego,
CA).

[17] NARAYANAN, A., PASKOV, H., GONG, N. Z., BETHEN-
COURT, J., CHUL, E., SHIN, R., AND SONG, D. On the
feasibility of internet-scale author identiﬁcation. In Pro-
ceedings of the 33rd conference on IEEE Symposium on
Security and Privacy. IEEE (San Francisco, CA, 2012).

[18] NATIONAL

VULNERABILITY

DATABASE.

https://nvd.nist.gov/.

[19] RALPH LANGNER. To kill a centrifuge: A technical anal-
ysis of what stuxnets creators tried to achieve. Tech. rep.,
2013.

[20] REUTERS.

Journalists,

from

hackers:

tack
www.reuters.com/article/2014/03/28/us-media-
cybercrime-idUSBREA2R0EU20140328.

media
Google

under
at-
researchers.

[21] SONG, D., BRUMLEY, D., YIN, H., CABALLERO, J.,
JAGER, I., KANG, M. G., LIANG, Z., NEWSOME, J.,
POOSANKAM, P., AND SAXENA, P. Bitblaze: A new ap-
proach to computer security via binary analysis. In Pro-
ceedings of the 4th International Conference on Informa-
tion Systems Security (Hyderabad, India, 2008).

[22] SYMANTEC.

2013

security
threat
rep.
http://www.symantec.com/security response/publications/
threatreport.jsp.

internet

volume

report,

Tech.

18.

[23] WIRED.

Google

hackers

source
http://www.wired.com/2010/01/google-hack-attack/.

of more

code

than

30

targeted
companies.

14

A Targeted organizations

Organization
World Uyghur Congress (WUC)
East Turkestan Union in Europe (ETUE)
Australian Uyghur Association
Euro-Asia Foundation in Turkey
Uyghur Canadian Association
Germany Uyghur Women Committee
Radio Free Asia (RFA)
France Uyghur Association
Eastern Turkestan Australian Association (ETAA)
Uyghur American Association (UAA)
Eastern Turkestan Uyghur Association in Netherlands
Netherland Uyghur Union
United Nations for a Free Tibet (UK)
Eastern Turkestan Culture and Solidarity Association
Viktoria Uyghur Association
Japan Uyghur Association
Switzerland East Turkestan Association
Hacettepe University Turkey
Kazakhstan Academy of Poetry
Belgium Uyghur Association
Kyrgyzstan Uyghur Association
Uyghur Canadian Society
Uyghur Academy
Munich Uyghur Elders Meshrep
Republican Uyghur Cultural Center of Kazakhstan
Sweden Uyghur Association
Virginia Department of Social Services
Unrepresented Nations and Peoples Organization (UNPO)
Sociale Verzekeringsbank (SVB) NGO Netherland
China Democratic Party (CDP)
Finland Uyghur Association
Jet Propulsion Laboratory, founded by NASA
Pennsylvania State University US
Uyghur Support Group Nederland
Norway Uyghur Committee
Amnesty International
Association of European Border Regions (AEBR)
Howard University US
Initiatives for China
LSE Asia Research Center and Silk Road Dialogue
The Government-in-Exile of the Republic of East Turkistan
Uyghur Human Rights Project (UHRP)
Australian Migration Options Pty Ltd
Agence France-Presse
National Endowment for Democracy (NED)
PEN International
Syracuse University US
Worldwide Protest in Honor and Support of Uyghurs Dying for Freedom
Australian Government - Department of Foreign Affairs and Trade
New Tang Dynasty Television China
The Epoch Times
Ministry of Foreign Affairs Norway
International University of Kagoshima Japan
Association of Islam Religion
Bilkent University Turkey
Embassy of Azerbaijan in Beijing
Indiana University School of Law-Indianapolis LL.M.
KYOCERA Document Solutions Development America
New York Times
Pﬁzer Government Research Laboratory - Clinical Pharmacology
Saudi Arabia - Luggage Bags and Cases Company
Students for a Free Tibet
Sweden Uyghur Education Union
Uyghur International Culture Center
The Protestant Church Amsterdam
Swiss Agency for Development and Cooperation (SDC) Kargyzstan
American Bar Association for Attorneys in US
Assistance for Work Germany Frankfurt
Bishkek Human Rights Committee
Central Tibetan Administration (CTA)
Chinese Translation Commercial Business
Circassian Cultural Center (CHKTS)
Colombian National Radio
Embassy of the United States in Australia
Europa Haber Newspaper Turkey
Europe-China Cultural Communication (ECCC)
Freelance Reporter and writer Turkey
Goethe University Frankfurt am Main Germany
Human Rights Campaign in China
International Enterprise (IE) - Singapore Government
International Tibet Independence Movement
Jasmine Revolution China (Pro-Democracy Protests)
Socialist Party (Netherlands)
Los Angeles Times
Milli Gazete (National Newspaper Turkey)
Norwegian Tibet Committee
Photographer Turkey
CNN International Hong Kong
Reporters Without Borders
Republican National Lawyers Association Maryland
Save Tibet - International Campaign for Tibet
Society for Threatened People (STPI)
Southern Mongolian Human Rights
Stucco Manufacturers Association US
Superior School of Arts France
The George Washington University
TurkishNews Newspaper
US Bureau of Transportation Statistics
Umit Uighur Language School
Union of Turkish-Islamic Cultural Associations in Europe
University of Adelaide Melbourne
University of Khartoum Sudan
US Embassy and Consulate in Munich Germany
Wei Jingsheng Foundation
Xinjiang Arts Institute China
Yenicag Gazetti (Newspaper Turkey)
American University
Islamic Jihad Union

# Recipients

# Emails

53
7
3
2
6
2
12
5
6
10
4
1
1
13
1
2
2
3
2
1
2
1
5
1
1
4
1
5
1
5
1
1
1
2
1
4
1
1
3
2
2
2
3
1
2
3
1
1
2
2
2
1
1
1
2
2
1
1
2
1
1
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

2,366
153
129
101
98
82
80
80
77
72
69
60
57
53
48
43
43
41
36
35
33
31
25
22
22
12
11
8
8
5
5
5
5
5
5
4
4
4
4
4
4
4
4
3
3
3
3
3
3
3
3
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

First-Last
2009-2013
2010-2013
2009-2013
2010-2013
2009-2013
2009-2013
2010-2013
2009-2013
2009-2013
2010-2013
2010-2013
2012-2013
2011-2013
2009-2013
2010-2013
2012-2013
2010-2013
2010-2013
2009-2013
2009-2013
2011-2013
2009-2013
2009-2013
2012-2013
2009-2013
2010-2013
2009-2012
2010-2013
2012-2013
2009-2011

2013
2012

2010-2013
2010-2013
2010-2013
2010-2012
2010-2011
2012-2013
2009-2010
2012-2013
2010-2011

2010
2010
2013

2010-2012
2009-2013

2013
2013
2010
2010
2010
2013
2013
2013

2011-2012

2010
2012
2013
2009

2011-2012

2013
2010

2010-2013

2012
2010
2013
2010
2010
2012
2010
2009
2012
2010
2010
2010
2011
2012
2012
2010
2010
2010
2009
2011
2010
2010
2010
2012
2012
2012
2010
2010
2012
2012
2013
2012
2013
2010
2009
2010
2012
2010
2012
2011
2009
2010
2010
2012
2012

B Dynamic taint-assisted analysis of mali-

cious documents

B.1 Methodology
We use BitBlaze [21] to perform dynamic taint-tracking analy-
sis of the targeted applications under the malicious documents
as input and conﬁgure it to report four kinds of reports: (a)
when a tainted Extended Instruction Pointer (EIP) is executed,
(b) when a memory fault is triggered in the target program, (c)
when a new process is spawned from the target program, or
(d) when the analysis “times out” (i.e., runs without interrup-
tion for over 15 minutes). To mark malicious documents as a
source of taint, we tainted the network inputs and routed the
malicious input ﬁle using netcat. Additionally, we set Bit-
Blaze to exit tracing at the detection of null pointer exceptions,
user exceptions, tainted EIPs, and process exits before the start
of the trace. A tag was generated from the trace by obtain-
ing the last instruction with tainted operands, and matching it
with the list of loaded modules generated by TEMU. Our guest
(analysis) system conﬁguration used in the image consists of
clean installations of Windows XP SP2 with TEMU drivers and
Microsoft Ofﬁce 2003.
B.2 Results
Anti-virus software typically uses static signature-matching or
whitelisting techniques to analyze malware. To validate the
analysis results available from commercial AV, we ran a sep-
arate semi-automated dynamic analysis of the targeted applica-
tion under our malicious documents.

Out of 817 unique input documents (725 malicious and 92
legitimate), 295 timed out with our BitBlaze analysis without
reporting a tainted EIP, a memory fault, or a newly spawned
process.2 Another 13 of them were incompatible with our anal-
ysis infrastructure (using a more recent DOCX format). We
could not compare these cases directly to the results obtained
from VirusTotal. Therefore, we focus on the remaining 509
malicious documents in the evaluation.
Efﬁcacy of Taint EIP Detection. Taint-tracking detected
tainted EIP execution in 477 out of the 509 documents.
In
19 cases of the undetected 32 cases, however, a new process
was spawned without it being detected by taint-tracking. We
treat these as false negatives in taint-tracking. We speculate
that this is likely to be due to missed direct ﬂows, untracked
indirect ﬂows (via control dependencies, or table-lookups), or
attacks using non-control-ﬂow hijacking attacks (such as argu-
ment corruption). 13 documents did not lead to a tainted EIP
execution, but instead caused a memory fault. This could be
due to a difference in our test infrastructure and the victim’s,
or an attempt to evade analysis. In 33 of the 477 cases where
tainted EIP was detected, no new spawned process was created,
and the tainted EIP instruction did not correspond to any shell-
code. All these cases correspond to a particular instruction trig-
gering the tainted EIP detection in MSO.DLL, a dynamic-link
library found in Microsoft Ofﬁce installations. To understand
this case better, we manually created blank benign documents
and fed them to Microsoft Ofﬁce — they too triggered tainted

2We believe 150 of these are due to user-interaction which we could
not presently automate, and the remaining could potentially be ana-
lyzed with a faster test platform; we plan to investigate this in the fu-
ture.

15

Figure 12: Breakdown of dynamic taint-assisted analy-
sis, and comparison to VirusTotal AV results. Single,
Multiple, Heuristics, and Unknown correspond to the dif-
ferent AV tags assigned to documents. The main bars
show the detection result from BitBlaze: (a) Detected
by Tainted EIP execution, (b) Timeout, (c) Spawned pro-
cess without tainted EIP execution, (d) Memory Fault
without tainted EIP execution, and (e) DOCX unable to
run in our analysis environment. Within each main bar,
each stacked bar represents the corresponding tag given
by VirusTotal.
EIP detections. We treat these cases as false positives in taint
detection, possibly because of benign dynamic generation of
code. All the remaining cases (i.e., 444 out of 477) are legiti-
mate exploits that we could conﬁrm to execute shellcode.
Dynamic Taint versus VirusTotal. Figure 12 shows the de-
tailed comparison of taint-assisted classiﬁcation of vulnera-
bilities versus the results from VirusTotal. Out of a total of
477 documents on which tainted EIP was detected, VirusTotal
tagged 397 documents with one or more CVEs. Of the remain-
ing 80 cases that are detected by tainted EIP execution, 24 are
undetected by VirusTotal, and 56 are detected, but marked Un-
known (i.e., no CVE assigned) by VirusTotal. Dynamic taint
analysis to determine the tainted EIP was helpful to further
reﬁne the results of AV detection for a majority of these 56
tagged-Unknown cases. Speciﬁcally, for 55 out of the 56 doc-
uments, taint-assisted manual analysis was able to resolve it to
the exploited CVE.

Out of a total of 477 documents on which tainted EIP was
detected, VirusTotal tagged 397 documents with one or more
CVEs. Our taint-assisted manual analysis agrees with the
VirusTotal CVE tag results on 372 of these 397. That is, 372
documents were detected to execute a tainted EIP for which we
could manually correlate to a single CVE that was the same as
the one reported by a majority of the AVs in VirusTotal.3 Thus,
for a large majority of the cases, taint-assisted analysis agrees
with the AV results. Of the remaining 25 cases, 17 could be
identiﬁed as misclassiﬁcations because the CVE reported by
most of the AVs in VirusTotal was not the one that affected
the program. The 8 remaining documents were tagged by taint
analysis as being false positives even though a CVE was ob-
tained from VirusTotal.

3Note that different AVs often tag the same vulnerability with dif-
ferent tags in VirusTotal. We took the tag given by a majority of the
reported tags, as the representative of the sample.

s
k
c
a

t
t

a

 
f

o

 

n
o

i
t
c
a
r
F

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

295

60

70

23

142

477

24

56

140

257

Unknown
Heuristic
Multiple
Single

19

3

16

13

1

12

 

13

8

5

Tainted

Timeout

Spawned

Fault

DOCX

C Command and Control (C2) servers

C2 # Emails

C2 # Emails

C2 # Emails

C2 # Emails

61.178.77.169 74
dtl.dnsd.me 66
ns.dns3-domain.com 55
dtl.eatuo.com 44
202.85.136.181 32
update.googmail.org 31
dtl6.mooo.com 29
www.discoverypeace.org 26
58.64.172.177 22
email.googmail.org 22
news.googmail.org 22
61.128.122.147 17
softmy.jkub.com 15
61.234.4.213 13
dnsmm.bpa.nu 11
121.170.178.221 10
zeropan007.3322.org 10
wwzzsh.3322.org 9
222.77.70.237 9
3.test.3322.org.cn 8
1.test.3322.org.cn 8
2.test.3322.org.cn 8
eemete.freetcp.com 8
apple12.crabdance.com 8
wolf001.us109.eoidc.net 7
4.test.3322.org.cn 7
etdt.cable.nu 6
205.209.159.162 6
br.stat-dns.com 6
66.79.188.23 6
www.southstock.net 6
ns1.3322.net 5
121.254.173.57 5
www.uyghur.25u.com 5
202.96.128.166 5
ns1.oray.net 5
jhska.cable.nu 5
test195.3322.org 5
61.234.4.218 5
61.128.110.37 5
ns1.china.com 5
a2010226.gicp.net 5
logonin.uyghuri.com 4
macaonews.8800.org 4
book.websurprisemail.com 4
desk.websurprisemail.com 4
test.3322.org.cn 4
221.239.82.21 4
liveservices.dyndns.info 4
180.169.28.58 4
portright.org 4
video.googmail.org 4
www.guzhijiaozihaha.net 4
207.46.11.22 4
www.googmail.org 4
2.test.3322.org 3
dcp.googmail.org 3
test.3322.org 3
np6.dnsrd.com 3

mzyzy.vicp.net 3
mygoodbug.dnsd.info 3
www.uyghuri.mrface.com 3
6.test.3322.org.cn 3
218.82.206.229 3
uyghur.sov.tw 3
3.test.3322.org 3
newwhitehouse.org 3
goodnewspaper.f3322.org 3
nskupdate.com 3
webmonder.gicp.net 3
61.132.74.68 3
61.178.77.108 3
betterpeony.com 3
4.test.3322.org 3
61.234.4.210 3
9.test.3322.org.cn 3
8.test.3322.org.cn 3
1.test.3322.org 3
radio.googmail.org 3
7.test.3322.org.cn 3
tokyo.collegememory.com 2
201.22.184.42 2
61.178.77.96 2
webproxy.serveuser.com 2
www.bbcnewes.net 2
done.youtubesitegroup.com 2
alma.apple.cloudns.org 2
webmailsvr.com 2
polat.googmail.org 2
religion.xicp.net 2
connectsexy.dns-dns.com 2
dns3.westcowboy.com 2
61.220.138.100 2
27.254.41.7 2
116.92.6.197 2
apple12.co.cc 2
58.64.129.149 2
worldmaprsh.com 2
phinex127.gicp.net 2
wxjz.6600.org 2
gecko.jkub.com 2
smtp.126.com 2
errorslog.com 2
uyghurie.51vip.biz 2
tanmii.gicp.net 2
211.115.207.7 2
59.188.5.19 2
206.196.106.85 2
religion.8866.org 2
68.89.135.192 2
blogging.blogsite.org 2
softjohn.ddns.us 2
report.dns-dns.com 2
115.160.188.245 2
newyorkonlin.com 2
tw252.gicp.net 2
61.222.31.54 2
tomsonmartin.ikwb.com 2

www.info-microsoft.com 2
www.uyhanur.nna.cc 2
www.micosofts.com 2
100.4.43.2 2
61.234.4.214 1
a.yahoohello.com 1
bc1516.7766.org 1
202.68.226.250 1
msdn.homelinux.org 1
207.204.245.192 1
216.131.66.96 1
www.avasters.com 1
202.130.112.231 1
nbsstt.3322.org 1
goodnewspaper.3322.org 1
webposter.gicp.net 1
uyghur1.webhop.net 1
webwx.3322.orgxiexie.8866.org 1
125.141.149.49 1
guanshan.3322.org 1
leelee.dnset.com 1
uygur.eicp.net 1
kxwss.8800.org 1
173.208.157.186 1
rc.arkinixik.com 1
www.uusuanru.nna.cc 1
uxz.fo.mooo.com 1
uygur.51vip.biz 1
peopleunion.gicp.net 1
free1000.gnway.net 1
uxz.fo.dnsd.info 1
wodebeizi119.jkub.com 1
itsec.eicp.net 1
stormgo.oicp.net 1
boy303.2288.org 1
webjz.9966.org 1
zbing.strangled.net 1
tommark5454.xxxy.info 1
oyghur1.webhop.net 1
addi.apple.cloudns.org 1
60.170.255.85 1
toolsbar.dns0755.net 1
61.132.74.113 1
113.10.201.250 1
home.grafﬁti.net 1
statistics.netrobots.org 1
freesky365.gnway.net 1
greta.ikwb.com 1
englishclub.2288.org 1
mm.utf888.com 1
annchan.mrface.com 1
www.shine.4pu.com 1
copy.apple.cloudns.org 1
220.171.107.138 1
uyghuri.mrface.com 1
218.108.42.59 1
58.64.193.228 1
tt9c.2288.org 1
forum.universityexp.com 1

16

googlehk.dynamicdns.co.uk 1
113.10.201.254 1
152.101.38.177 1
blog.sina.com.cn 1
uyghur.epac.to 1
xinxin20080628.gicp.net 1
yah00mail.gicp.net 1
hbnjx.6600.org 1
humanbeing2009.gicp.net 1
webhelp01.freetcp.com 1
mobile.yourtrap.com 1
125.141.149.23 1
222.73.27.223 1
www.jiapin.org 1
ibmcorp.slyip.com 1
182.16.11.187 1
star2.ksksz.com 1
69.197.132.130 1
www.yahooprotect.com 1
xiexie.8866.org 1
img.mic-road.com 1
photo.googmail.org 1
tonylee38.gicp.net 1
suggest.dns1.us 1
worldview.instanthq.com 1
goodnewspaper.gicp.net 1
112.121.182.150 1
abc69696969.vicp.net 1
put.adultdns.net 1
loadbook.strangled.net 1
internet.3-a.net 1
news.scvhosts.com 1
98.126.20.221 1
mydeyuming.cable.nu 1
gshjl.3322.org 1
forever001.dtdns.net 1
grt1.25u.com 1
66.197.202.242 1
kaba.wikaba.com 1
221.239.96.180 1
174.139.133.58 1
125.141.149.46 1
frank.3feet.com 1
115.126.3.214 1
liveservices.dyndns.tv 1
inc.3feet.com 1
1nsmm.bpa.nu 1
www.yahooprotect.net 1
222.82.220.118 1
webwxjz.3322.org 1
61.234.4.220 1
thankyou09.gicp.net 1
218.28.72.138 1
soft.epac.to 1
www.yahooip.net 1
msejake.7766.org 1
202.67.215.143 1
www.yahoohello.com 1
202.109.121.138 1

